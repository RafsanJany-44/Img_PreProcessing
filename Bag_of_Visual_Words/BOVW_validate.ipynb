{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pylab as pl\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score #sreeni\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classifier, class names, scaler, number of clusters and vocabulary \n",
    "#from stored pickle file (generated during training)\n",
    "clf, classes_names, stdSlr, k, voc = joblib.load(\"bovw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path of the testing image(s) and store them in a list\n",
    "#test_path = 'dataset/test' # Names are Aeroplane, Bicycle, Car\n",
    "test_path = \"C:/Users/RAZER/Downloads/dataset/Micro_Organism/Set_1/val\"  # Folder Names are Parasitized and Uninfected\n",
    "#instead of test if you use train then we get great accuracy\n",
    "\n",
    "testing_names = os.listdir(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amoeba',\n",
       " 'Euglena',\n",
       " 'Hydra',\n",
       " 'Paramecium',\n",
       " 'Rod_bacteria',\n",
       " 'Spherical_bacteria',\n",
       " 'Spiral_bacteria',\n",
       " 'Yeast']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path to all images and save them in a list\n",
    "# image_paths and the corresponding label in image_paths\n",
    "image_paths = []\n",
    "image_classes = []\n",
    "class_id = 0\n",
    "\n",
    "#To make it easy to list all file names in a directory let us define a function\n",
    "#\n",
    "def imglist(path):\n",
    "    return [os.path.join(path, f) for f in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill the placeholder empty lists with image path, classes, and add class ID number\n",
    "\n",
    "for testing_name in testing_names:\n",
    "    dir = os.path.join(test_path, testing_name)\n",
    "    class_path = imglist(dir)\n",
    "    image_paths+=class_path\n",
    "    image_classes+=[class_id]*len(class_path)\n",
    "    class_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature extraction and keypoint detector objects\n",
    "    #SIFT is not available anymore in openCV    \n",
    "# Create List where all the descriptors will be stored\n",
    "des_list = []\n",
    "\n",
    "#BRISK is a good replacement to SIFT. ORB also works but didn;t work well for this example\n",
    "brisk = cv2.BRISK_create(30)\n",
    "\n",
    "for image_path in image_paths:\n",
    "    im = cv2.imread(image_path)\n",
    "    kpts, des = brisk.detectAndCompute(im, None)\n",
    "    des_list.append((image_path, des))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack all the descriptors vertically in a numpy array\n",
    "descriptors = des_list[0][1]\n",
    "for descriptor in des_list[0:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30713, 64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2])\n",
    "b = np.array([3, 4])\n",
    "\n",
    "\n",
    "c = np.vstack((a, b))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [2, 4]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.column_stack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Banded_krait",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
