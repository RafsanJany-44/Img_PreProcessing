{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Pixel Processing, VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: good for small data,and weaker resources, good for large images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making label: www.apeer.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D\n",
    "import os\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['128_patches', 'mask', 'train']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"C:/Users/RAZER/Downloads/dataset/sandstone_data_for_ML/sandstone_data_for_ML/full_labels_for_deep_learning\"))\n",
    "#SIZE = 512 #Resize images\n",
    "path = \"C:/Users/RAZER/Downloads/dataset/sandstone_data_for_ML/sandstone_data_for_ML/full_labels_for_deep_learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing images is optional, CNNs are ok with large images\n",
    "SIZE_X = 1024 #Resize images (height  = X, width = Y)\n",
    "SIZE_Y = 996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capture training image info as a list\n",
    "train_images = []\n",
    "\n",
    "for directory_path in glob.glob(path+\"/train\"):\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.tif\")):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "        img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        train_images.append(img)\n",
    "        #train_labels.append(label)\n",
    "#Convert list to array for machine learning processing        \n",
    "train_images = np.array(train_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capture mask/label info as a list\n",
    "train_masks = [] \n",
    "for directory_path in glob.glob(path+\"/mask\"):\n",
    "    for mask_path in glob.glob(os.path.join(directory_path, \"*.tif\")):\n",
    "        mask = cv2.imread(mask_path, 0)       \n",
    "        mask = cv2.resize(mask, (SIZE_Y, SIZE_X))\n",
    "        #mask = cv2.cvtColor(mask, cv2.COLOR_RGB2BGR)\n",
    "        train_masks.append(mask)\n",
    "        #train_labels.append(label)\n",
    "#Convert list to array for machine learning processing          \n",
    "train_masks = np.array(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use customary x_train and y_train variables\n",
    "X_train = train_images\n",
    "y_train = train_masks\n",
    "y_train = np.expand_dims(y_train, axis=3) #May not be necessary.. leftover from previous code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Banded_krait",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
