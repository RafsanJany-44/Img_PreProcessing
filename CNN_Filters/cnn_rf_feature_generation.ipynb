{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['128_patches', 'train_imgs_cropped_768.tif', 'train_masks_grey_cropped_768.tif']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"C:/Users/RAZER/Downloads/dataset/sandstone_data_for_ML/sandstone_data_for_ML/full_labels_for_deep_learning\"))\n",
    "SIZE = 512 #Resize images\n",
    "path = \"C:/Users/RAZER/Downloads/dataset/sandstone_data_for_ML/sandstone_data_for_ML/full_labels_for_deep_learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "\n",
    "for directory_path in glob.glob(path+\"/train\"):\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.tif\")):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        train_images.append(img)\n",
    "        #train_labels.append(label)\n",
    "        \n",
    "train_images = np.array(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_masks = [] \n",
    "for directory_path in glob.glob(path+\"/mask\"):\n",
    "    for mask_path in glob.glob(os.path.join(directory_path, \"*.tif\")):\n",
    "        mask = cv2.imread(mask_path, 0)       \n",
    "        mask = cv2.resize(mask, (SIZE, SIZE))\n",
    "        #mask = cv2.cvtColor(mask, cv2.COLOR_RGB2BGR)\n",
    "        train_masks.append(mask)\n",
    "        #train_labels.append(label)\n",
    "        \n",
    "train_masks = np.array(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_images\n",
    "y_train = train_masks\n",
    "y_train = np.expand_dims(y_train, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = 'sigmoid'\n",
    "feature_extractor = Sequential()\n",
    "feature_extractor.add(Conv2D(32, 3, activation = activation, padding = 'same', input_shape = (SIZE, SIZE, 3)))\n",
    "feature_extractor.add(Conv2D(32, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "\n",
    "#feature_extractor.add(Conv2D(64, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "#feature_extractor.add(BatchNormalization())\n",
    "#\n",
    "#feature_extractor.add(Conv2D(64, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "#feature_extractor.add(BatchNormalization())\n",
    "#feature_extractor.add(MaxPooling2D())\n",
    "#feature_extractor.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 512, 512, 32)      896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 512, 512, 32)      9248      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,144\n",
      "Trainable params: 10,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 168ms/step\n"
     ]
    }
   ],
   "source": [
    "X = feature_extractor.predict(X_train)\n",
    "\n",
    "X = X.reshape(-1, X.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = y_train.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "3    180611\n",
      "1     53610\n",
      "2     21304\n",
      "4      6619\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.DataFrame(X)\n",
    "dataset['Label'] = Y\n",
    "print(dataset['Label'].unique())\n",
    "print(dataset['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.584645</td>\n",
       "      <td>0.502616</td>\n",
       "      <td>0.459412</td>\n",
       "      <td>0.590496</td>\n",
       "      <td>0.665266</td>\n",
       "      <td>0.563414</td>\n",
       "      <td>0.498667</td>\n",
       "      <td>0.575569</td>\n",
       "      <td>0.430250</td>\n",
       "      <td>0.369482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631613</td>\n",
       "      <td>0.608993</td>\n",
       "      <td>0.627468</td>\n",
       "      <td>0.837663</td>\n",
       "      <td>0.646095</td>\n",
       "      <td>0.535825</td>\n",
       "      <td>0.676341</td>\n",
       "      <td>0.540437</td>\n",
       "      <td>0.538257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.583126</td>\n",
       "      <td>0.388469</td>\n",
       "      <td>0.412190</td>\n",
       "      <td>0.666677</td>\n",
       "      <td>0.706150</td>\n",
       "      <td>0.672012</td>\n",
       "      <td>0.442845</td>\n",
       "      <td>0.576429</td>\n",
       "      <td>0.489001</td>\n",
       "      <td>0.397732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.611252</td>\n",
       "      <td>0.591033</td>\n",
       "      <td>0.659870</td>\n",
       "      <td>0.810151</td>\n",
       "      <td>0.643225</td>\n",
       "      <td>0.551585</td>\n",
       "      <td>0.766183</td>\n",
       "      <td>0.533400</td>\n",
       "      <td>0.552836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.583126</td>\n",
       "      <td>0.388469</td>\n",
       "      <td>0.412190</td>\n",
       "      <td>0.666677</td>\n",
       "      <td>0.706150</td>\n",
       "      <td>0.672012</td>\n",
       "      <td>0.442845</td>\n",
       "      <td>0.576429</td>\n",
       "      <td>0.489001</td>\n",
       "      <td>0.397732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.611252</td>\n",
       "      <td>0.591033</td>\n",
       "      <td>0.659870</td>\n",
       "      <td>0.810151</td>\n",
       "      <td>0.643225</td>\n",
       "      <td>0.551585</td>\n",
       "      <td>0.766183</td>\n",
       "      <td>0.533400</td>\n",
       "      <td>0.552836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.583126</td>\n",
       "      <td>0.388469</td>\n",
       "      <td>0.412190</td>\n",
       "      <td>0.666677</td>\n",
       "      <td>0.706150</td>\n",
       "      <td>0.672012</td>\n",
       "      <td>0.442845</td>\n",
       "      <td>0.576429</td>\n",
       "      <td>0.489001</td>\n",
       "      <td>0.397732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.611252</td>\n",
       "      <td>0.591033</td>\n",
       "      <td>0.659870</td>\n",
       "      <td>0.810151</td>\n",
       "      <td>0.643225</td>\n",
       "      <td>0.551585</td>\n",
       "      <td>0.766183</td>\n",
       "      <td>0.533400</td>\n",
       "      <td>0.552836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.583126</td>\n",
       "      <td>0.388469</td>\n",
       "      <td>0.412190</td>\n",
       "      <td>0.666677</td>\n",
       "      <td>0.706150</td>\n",
       "      <td>0.672012</td>\n",
       "      <td>0.442845</td>\n",
       "      <td>0.576429</td>\n",
       "      <td>0.489001</td>\n",
       "      <td>0.397732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.611252</td>\n",
       "      <td>0.591033</td>\n",
       "      <td>0.659870</td>\n",
       "      <td>0.810151</td>\n",
       "      <td>0.643225</td>\n",
       "      <td>0.551585</td>\n",
       "      <td>0.766183</td>\n",
       "      <td>0.533400</td>\n",
       "      <td>0.552836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262139</th>\n",
       "      <td>0.601231</td>\n",
       "      <td>0.565615</td>\n",
       "      <td>0.423665</td>\n",
       "      <td>0.599409</td>\n",
       "      <td>0.692633</td>\n",
       "      <td>0.681778</td>\n",
       "      <td>0.452668</td>\n",
       "      <td>0.623456</td>\n",
       "      <td>0.465042</td>\n",
       "      <td>0.390586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743749</td>\n",
       "      <td>0.296571</td>\n",
       "      <td>0.626258</td>\n",
       "      <td>0.639250</td>\n",
       "      <td>0.807050</td>\n",
       "      <td>0.521953</td>\n",
       "      <td>0.550127</td>\n",
       "      <td>0.433266</td>\n",
       "      <td>0.377462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262140</th>\n",
       "      <td>0.601231</td>\n",
       "      <td>0.565615</td>\n",
       "      <td>0.423665</td>\n",
       "      <td>0.599409</td>\n",
       "      <td>0.692633</td>\n",
       "      <td>0.681778</td>\n",
       "      <td>0.452668</td>\n",
       "      <td>0.623456</td>\n",
       "      <td>0.465042</td>\n",
       "      <td>0.390586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743749</td>\n",
       "      <td>0.296571</td>\n",
       "      <td>0.626258</td>\n",
       "      <td>0.639250</td>\n",
       "      <td>0.807050</td>\n",
       "      <td>0.521953</td>\n",
       "      <td>0.550127</td>\n",
       "      <td>0.433266</td>\n",
       "      <td>0.377462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262141</th>\n",
       "      <td>0.601231</td>\n",
       "      <td>0.565615</td>\n",
       "      <td>0.423665</td>\n",
       "      <td>0.599409</td>\n",
       "      <td>0.692633</td>\n",
       "      <td>0.681778</td>\n",
       "      <td>0.452668</td>\n",
       "      <td>0.623456</td>\n",
       "      <td>0.465042</td>\n",
       "      <td>0.390586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743749</td>\n",
       "      <td>0.296571</td>\n",
       "      <td>0.626258</td>\n",
       "      <td>0.639250</td>\n",
       "      <td>0.807050</td>\n",
       "      <td>0.521953</td>\n",
       "      <td>0.550127</td>\n",
       "      <td>0.433266</td>\n",
       "      <td>0.377462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262142</th>\n",
       "      <td>0.601231</td>\n",
       "      <td>0.565615</td>\n",
       "      <td>0.423665</td>\n",
       "      <td>0.599409</td>\n",
       "      <td>0.692633</td>\n",
       "      <td>0.681778</td>\n",
       "      <td>0.452668</td>\n",
       "      <td>0.623456</td>\n",
       "      <td>0.465042</td>\n",
       "      <td>0.390586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743749</td>\n",
       "      <td>0.296571</td>\n",
       "      <td>0.626258</td>\n",
       "      <td>0.639250</td>\n",
       "      <td>0.807050</td>\n",
       "      <td>0.521953</td>\n",
       "      <td>0.550127</td>\n",
       "      <td>0.433266</td>\n",
       "      <td>0.377462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262143</th>\n",
       "      <td>0.583030</td>\n",
       "      <td>0.548272</td>\n",
       "      <td>0.421014</td>\n",
       "      <td>0.514904</td>\n",
       "      <td>0.633971</td>\n",
       "      <td>0.578691</td>\n",
       "      <td>0.504395</td>\n",
       "      <td>0.520518</td>\n",
       "      <td>0.450999</td>\n",
       "      <td>0.371327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632671</td>\n",
       "      <td>0.351350</td>\n",
       "      <td>0.635890</td>\n",
       "      <td>0.495441</td>\n",
       "      <td>0.789877</td>\n",
       "      <td>0.440828</td>\n",
       "      <td>0.543192</td>\n",
       "      <td>0.348437</td>\n",
       "      <td>0.499492</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262144 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0       0.584645  0.502616  0.459412  0.590496  0.665266  0.563414  0.498667   \n",
       "1       0.583126  0.388469  0.412190  0.666677  0.706150  0.672012  0.442845   \n",
       "2       0.583126  0.388469  0.412190  0.666677  0.706150  0.672012  0.442845   \n",
       "3       0.583126  0.388469  0.412190  0.666677  0.706150  0.672012  0.442845   \n",
       "4       0.583126  0.388469  0.412190  0.666677  0.706150  0.672012  0.442845   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "262139  0.601231  0.565615  0.423665  0.599409  0.692633  0.681778  0.452668   \n",
       "262140  0.601231  0.565615  0.423665  0.599409  0.692633  0.681778  0.452668   \n",
       "262141  0.601231  0.565615  0.423665  0.599409  0.692633  0.681778  0.452668   \n",
       "262142  0.601231  0.565615  0.423665  0.599409  0.692633  0.681778  0.452668   \n",
       "262143  0.583030  0.548272  0.421014  0.514904  0.633971  0.578691  0.504395   \n",
       "\n",
       "               7         8         9  ...        23        24        25  \\\n",
       "0       0.575569  0.430250  0.369482  ...  0.631613  0.608993  0.627468   \n",
       "1       0.576429  0.489001  0.397732  ...  0.611252  0.591033  0.659870   \n",
       "2       0.576429  0.489001  0.397732  ...  0.611252  0.591033  0.659870   \n",
       "3       0.576429  0.489001  0.397732  ...  0.611252  0.591033  0.659870   \n",
       "4       0.576429  0.489001  0.397732  ...  0.611252  0.591033  0.659870   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "262139  0.623456  0.465042  0.390586  ...  0.743749  0.296571  0.626258   \n",
       "262140  0.623456  0.465042  0.390586  ...  0.743749  0.296571  0.626258   \n",
       "262141  0.623456  0.465042  0.390586  ...  0.743749  0.296571  0.626258   \n",
       "262142  0.623456  0.465042  0.390586  ...  0.743749  0.296571  0.626258   \n",
       "262143  0.520518  0.450999  0.371327  ...  0.632671  0.351350  0.635890   \n",
       "\n",
       "              26        27        28        29        30        31  Label  \n",
       "0       0.837663  0.646095  0.535825  0.676341  0.540437  0.538257      1  \n",
       "1       0.810151  0.643225  0.551585  0.766183  0.533400  0.552836      1  \n",
       "2       0.810151  0.643225  0.551585  0.766183  0.533400  0.552836      1  \n",
       "3       0.810151  0.643225  0.551585  0.766183  0.533400  0.552836      1  \n",
       "4       0.810151  0.643225  0.551585  0.766183  0.533400  0.552836      1  \n",
       "...          ...       ...       ...       ...       ...       ...    ...  \n",
       "262139  0.639250  0.807050  0.521953  0.550127  0.433266  0.377462      1  \n",
       "262140  0.639250  0.807050  0.521953  0.550127  0.433266  0.377462      1  \n",
       "262141  0.639250  0.807050  0.521953  0.550127  0.433266  0.377462      1  \n",
       "262142  0.639250  0.807050  0.521953  0.550127  0.433266  0.377462      1  \n",
       "262143  0.495441  0.789877  0.440828  0.543192  0.348437  0.499492      1  \n",
       "\n",
       "[262144 rows x 33 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##If we do not want to include pixels with value 0 \n",
    "##e.g. Sometimes unlabeled pixels may be given a value 0.\n",
    "dataset = dataset[dataset['Label'] != 0]\n",
    "\n",
    "X_for_RF = dataset.drop(labels = ['Label'], axis=1)\n",
    "Y_for_RF = dataset['Label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators = 50, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on training data\n",
    "# Ravel Y to pass 1d array instead of column vector\n",
    "model.fit(X_for_RF, Y_for_RF) #For sklearn no one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'RF_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Banded_krait",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
